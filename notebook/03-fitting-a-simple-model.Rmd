# Fitting a simple model {#simple-model}

The goal of this section is to fit a simple model for income in order to introduce the modified Besag-York-Mollie model (BYM 2) and the SPDE model.

In both case, the general process is the same:

1.  Define the spatial dependency
2.  Split the model into a training and validation set
3.  Specify the formula expressing the outcome variables in terms of fixed and random spatial effects
4.  Fit the model on the training set
5.  Validate the model on the validation set.

The fixed effects are the covariates (e.g. population density or light at night). The spatial random effects are spatially correlated random effect used to model the spatial dependency. 

Note that it is assumed here that the list of fixed effects is known. Next section will present a backward stepwise covariate selection process to select the list of covariates.

## Loading the data
We start by loading the covariates data and matching them with the *segmento* spatial polygon data frame. 

```{r message=FALSE,warning=FALSE}
rm(list=ls())
library(parallel)
library(INLA)
library(dplyr)
#INLA:::inla.dynload.workaround()

# modify dir_data to where you stored the data
root_dir="~/"
project_dir="data/"

dir_data=paste0(root_dir,project_dir)

# load the data ####
ehpm17_predictors=read.csv(paste0(dir_data,
                                  "out/all_covariates_and_outcomes.csv"))

# correct for xls missbehaviour: the SEG_ID with a leading 0 were shorten
ehpm17_predictors=ehpm17_predictors%>%
  mutate(SEG_ID=as.character(SEG_ID),
         SEG_ID=ifelse(nchar(SEG_ID)==7,
                       paste0(0,SEG_ID),
                       SEG_ID))

# shape
segmento_sh=rgdal::readOGR(paste0(dir_data,
                                  "spatial/shape/admin/STPLAN_Segmentos.shp"))

# add the survey data to shapefile
segmento_sh_data=segmento_sh

segmento_sh_data@data=segmento_sh_data@data%>%
  # dplyr::select(SEG_ID)%>%
  mutate(SEG_ID=as.character(SEG_ID))%>%
  left_join(ehpm17_predictors,
            by="SEG_ID")
```

## Area data

### Spatial dependency with *area data* data
In order to model the spatial dependency with *area data* data, we need to inform the model about which *segmentos* are neighboring which ones. 

The function `spdep::poly2nb` creates a neighbours list from the *segmento* polygon. The list is created in a spatial format suitable for `INLA` with the function `spdep::nb2INLA`. It is then read as a graph-object for `INLA` consumption.

```{r eval=FALSE}
# define the neighbouring structure #### 
segmento_sh_data@data$ID=1:length(segmento_sh_data@data$n_obs)

segmento.nb=spdep::poly2nb(segmento_sh_data)
spdep::nb2INLA(paste0(dir_data,
                      "out/SEG.graph"),
               segmento.nb)
SEG.adj=paste0(paste0(dir_data,
                      "out/SEG.graph"),
               sep="")
Segmento.Inla.nb <- INLA::inla.read.graph(paste0(dir_data,
                                                 "out/SEG.graph"))
```

```{r echo=FALSE}
# define the neighbouring structure #### 
segmento_sh_data@data$ID=1:nrow(segmento_sh_data@data)

# segmento.nb=spdep::poly2nb(segmento_sh_data)
# spdep::nb2INLA(paste0(dir_data,
#                       "out/SEG.graph"),
#                segmento.nb)
# SEG.adj=paste0(paste0(dir_data,
#                       "out/SEG.graph"),
#                sep="")
Segmento.Inla.nb <- INLA::inla.read.graph(paste0(dir_data,
                                                 "out/SEG.graph"))
```

Fig. \@ref(fig:neigh) illustrates the results with Departmental level data.

```{r echo=FALSE, message=FALSE,warning=FALSE}
departamentos_sh=rgdal::readOGR(paste0(dir_data,
                                  "spatial/shape/admin/STPLAN_Departamentos.shp"))
departamentos_sh@data$ID=1:nrow(departamentos_sh@data)

departamentos.nb=spdep::poly2nb(departamentos_sh)
spdep::nb2INLA(paste0(dir_data,
                      "out/DEP.graph"),
               departamentos.nb)
DEP.adj=paste0(paste0(dir_data,
                      "out/DEP.graph"),
               sep="")
DEP.Inla.nb <- INLA::inla.read.graph(paste0(dir_data,
                                                 "out/DEP.graph"))
Coords=coordinates(departamentos_sh)
```
```{r neigh, echo=FALSE,out.width = '100%',fig.cap='Neigbouring structure at the Departmental level'}
plot(departamentos_sh,border=grey(0.5))
plot(departamentos.nb,
     coords=Coords,
     add=T,
     pch=16,
     lwd=1)
```

### Store the data for modelling
The data are stored in a dataframe `data_model`.

```{r include=FALSE,echo=FALSE}
segmento_sh_data@data=segmento_sh_data@data%>%
  select(-c(AREA_ID.y))%>%
  rename("AREA_ID"="AREA_ID.x")
```

```{r}
# identify ehpm17 segmentos to fit the model ####
segmento_sh_data_model=segmento_sh_data 

non_na_index=which(is.na(segmento_sh_data_model$n_obs)==F)

ehpm17_predictors_nona=segmento_sh_data_model@data[non_na_index,]


# covariates #####
cov_candidates_selected_df=read.table(paste0(dir_data,
                                             "out/distance_corr_var/selected_all.txt"),
                                      header =T)
cov_candidates_selected_table=cov_candidates_selected_df
names(cov_candidates_selected_table)="Candidates"
# knitr::kable(
#   cov_candidates_selected_table,
#   caption = 'Candidate covariates for income',
#   booktabs = TRUE
# )
covariates=ehpm17_predictors_nona[,as.character(cov_candidates_selected_table$Candidates)]

# store data for the model ####
data_model=data.frame(ingpe=ehpm17_predictors_nona$ingpe,
                      intercept=array(1,dim(covariates)[1]), # intercept for INLA
                      ID=ehpm17_predictors_nona$ID, # ID to link data to the neibhouring structure
                      covariates)
```

### Split the sample into a 80/20 training and validation sets
The observations in the dataset are split into a 80/20 training and validation sets. The model will be fitted on the training set. Income will be predicted on the validation sets. Predicted values will be compared with the observed values of the validation set in order to assess the goodness of it of the model. 

```{r  eval=TRUE}
# sample segmentos for training, validation and test  ####
set.seed(1234)
spec = c(train = .8, validate = .2)
g = sample(cut(
  seq(nrow(data_model)), 
  nrow(data_model)*cumsum(c(0,spec)),
  labels = names(spec)
))
index_val=which(g=="validate")
index_train=which(g=="train")

data_model$pred=data_model$ingpe
data_model$pred[c(index_val)] <- NA # set the validation pred to NA: they will be predicted by the model and compared with observed values 
```

### Formula specifying the relationship between the outcome variable and the fixed and spatial random effects  
We write below a formula to predict income with a subset of the covariates. We chose to use the following set of covariates:

*   Binary indicator for rural and urban *segmentos*
*   Median lights at night
*   Population density
*   Average slope in the segmentos 
*   Average precipitation
*   Distance to public services
*   Distance to businesses
*   Distance to roads
 
```{r  eval=TRUE}
# write the test formula ####
formula_test =pred~ 
  AREA_ID+lights_med+pop_dens+slope+chirps_ev_2017+dist2pubamen+dist2road+
  f(ID,
    model = "bym2",
    graph = Segmento.Inla.nb,
    hyper=list(
      prec = list(prior = "pc.prec", param = c(0.1, 0.0001)),
      phi  = list(prior = "pc", param = c(0.5, 0.5))),
    scale.model = TRUE,
    constr = T,
    adjust.for.con.comp = T)
```

The variable `pred` is the output variable we aim to model, i.e. income.

The selected covariates are linearly added. Remember that they have been standardized in the previous section in order to avoid any issue linked to scale. These covariates are called fixed effects. 

The most complex bit of the formula is the spatial dependence structure specified in `f()`.

The `ID` is the *segmento* identifiers linking the graph object `Segmento.Inla.nb`, where the neigbouring structure is defined, with the dataframe where the covariates and output data are stored. The `model` parameter for the specification of the spatial correlation model that should be used. The `bym2` is used as it flexible and allows for a *relatively* intuitive specification of spatial random effects. 

The flexibility comes from the fact that `bym2` allows for the error term to be composed of two elements: (1) a pure random noise, (2) a spatially correlated noise. The penalized complexity (PC) priors `phi` allows to influence the importance of each effect (if `phi`=0, then we have pure noise, if `phi`=1, we only have spatially correlated random effect). 

The `prec` parameter is the precision parameters, i.e. how much the spatially correlated noise is allowed to vary spatially. If the value is high, then the spatially correlated noise is allowed to vary a lot across space and vice versa. By decreasing the PC prior on the precision parameter, one decreases the risk of over-fitting: less of the spatial variation left unexplained by the covariates is attributed to the spatial random effects and, as results, the model is better able to generalise to areas where it was not trained. 

Here, we have chosen to set the PC prior on precision as $Pr(\sigma>1)=0.0001$ instead of the default $Pr(\sigma>1)=0.01$. Indeed, we were facing over-fitting issues with the default priors: the difference between the goodness of fit in the training and validation set was very large (circa 20% in the $R^{2}$). 

### Fit the model on the training set 
The model is fitted with the `inla` command. We have to specify the likelihood distribution of the response variable. 

The `family` argument defines the type of likelihood function for the response variable. As the distribution of income is strictly positive and right skewed, a *Gamma* distribution is a good option option. 

The `data` argument specifies the data on which the model is fitted, in our case, it is the `data_model` dataframe.

As we use a *Gamma* likelihood function, the predicted values needs to be back transformed to the original scale by using the exponential function. The `control.predictor` allows automatise the process once the option `list(link=1,compute=T)` is specified.

We use a simple integration strategy to compute the posterior marginals of the model parameters by specifying `control.inla =list(int.strategy = "eb")`, where `eb` stands for "empirical Bayes". In the empirical Bayes approach, one use only one "integration point equal to the posterior mode of the hyperparameters" [@moraga2019geospatial]. This speeds up the estimation of the model.

```{r message=FALSE,warning=FALSE, eval=TRUE}
# fit the model on the training set ####
start_time=Sys.time() # time the start of the estimation
bym.res=inla(formula=formula_test, 
             family = "gamma", 
             data = data_model,
             control.predictor=list(link=1,compute=T), 
             control.inla =list(int.strategy = "eb"))
end_time=Sys.time() # time at the end of the estimation
duration=end_time-start_time 
print(duration)
```
The model took 3.7 minutes to be estimated. With the default integration strategy, the model takes 13.5 minutes to be estimated. No significant difference were found between both integration strategies.

### Validate the model on the validation set
The goodness of fit of the model can now be investigated on the validation set. We start by extracting the fitted values. The fitted values are stored in the `bym.res` object under `summary.fitted.values`. The `inla` model yield a distribution of predicted income for each *segmento*. Various statistics summarising this prediction are available for each *segmento*:

*   The mean fitted value
*   The median fitted value
*   The 2.5 and 97.5 percentile of the fitted values
*   The standard deviation of the fitted value distribution

We select below the mean fitted value, i.e. the mean prediction value for each *segmento*.
```{r  eval=TRUE}
# Extract the fitted values  ####
M_fit=bym.res$summary.fitted.values[,"mean"]
```

We can now compute the Root Mean Square Error (RMSE) and the pseudo $R^{2}$ as shown below.^[we will refer to the pseudo $R^{2}$ as the $R^{2}$  in the report. The pseudo $R^{2}$ is preferd to the *normal* $R^{2}$ (squared correlation between the fitted and observed values) as it allows for better comparison with non-linear model.] 
```{r  eval=TRUE}
RMSE=function(set,outcome,data,fit){
  res = data[set,outcome]-fit[set]
  RMSE_val <- sqrt(mean(res^2,na.rm=T)) 
  return(RMSE_val)  
}

pseudo_r2=function(set,outcome,data,fit){
  res =  data[set,outcome]-fit[set]
  RRes=sum((res)^2,na.rm = T)
  RRtot=sum((data[set,outcome]-mean(fit[set],na.rm=T))^2,na.rm = T)
  pseudo_r2_val=1-RRes/RRtot
  return(pseudo_r2_val)  
}

RMSE_val=RMSE(index_val,"ingpe",data_model,M_fit)
RMSE_train=RMSE(index_train,"ingpe",data_model,M_fit)

r2_val=pseudo_r2(index_val,"ingpe",data_model,M_fit)
r2_train=pseudo_r2(index_train,"ingpe",data_model,M_fit)
```

```{r bym2-fit-chunck, eval=T, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Observed vs predicted income values, BYM 2 model', out.width='80%', fig.width=3, fig.height=3,fig.show='hold',fig.align='center'}
a <- list(
  x = 600,
  y = 100,
  text = paste("R2 training set:",round(r2_train*100),"%",
               "\nR2 validation set:",round(r2_val*100),"%",
               "\n",
               "\nRMSE training set:",round(RMSE_train),"USD",
               "\nRMSE validation set:",round(RMSE_val),"USD"),
  
  xref = "x",
  yref = "y",
  showarrow = F)

plotly::plot_ly(y=M_fit[-index_val],
                x=data_model$ingpe[-index_val],
                type="scatter",
                mode="markers",
                name="training set",
                marker = list(color = 'black',
                              opacity = 0.3))%>%
  plotly::add_trace(y=M_fit[index_val],
                    x=data_model$ingpe[index_val],
                    mode="markers",
                    name="validation set",
                    marker = list(color = 'red',
                                  opacity = 0.3))%>%
  plotly::add_trace(y=c(0,880),
                    x=c(0,880),
                    type="scatter",
                    mode="lines",
                    name="1:1")%>%
  plotly::layout(yaxis=list(range=c(0,510),title="predicted (USD)"),
                 xaxis=list(range=c(0,880),title="observed (USD)"),
                 annotations=a,
                 title="Income at the segmento level")
```


```{r bym2-fit, echo=FALSE,out.width = '100%',fig.cap='Observed vs predicted income values, BYM 2 model'}
knitr::include_graphics("img/mini_model_0.PNG")
```

Fig. \@ref(fig:bym2-fit) shows the predicted against the observed income value for the training and validation set. The model appears to do a relatively good job, although it has difficulty to capture the *segmentos* with an income above 400.

A $R^{2}$ of 44% is relatively satisfactory. It means that 44% of the income variation in the validation set is explained by the model fitted on the training set. However, the fact that the $R^{2}$ is at 69%, close to twice as big as the $R^{2}$ in the validation set, indicates over-fitting. 

The RMSE is 66 USD in the validation set and 40 usd in the training set. The RMSE is the standard deviation of the residuals, the difference between the fitted and observed values.  

The results are stored in a list and saved in a `.RData` file for later consumption.
```{r  eval=TRUE}
income_bym2_naive=list("outcome"="ingpe",
                       "spat_dep"="bym2",
                       "cov_select"="naive",
                       "formula"=formula_test,
                       "family"="gamma",
                       "data"=data_model,
                       "fit"=M_fit,
                       "index_val"=index_val,
                       "index_train"=index_train,
                       "r2_val"=r2_val,
                       "r2_train"=r2_train,
                       "RMSE_val"=RMSE_val,
                       "RMSE_train"=RMSE_train)
save(income_bym2_naive,
     file=paste0(dir_data,
            "out/results/income_bym2_naive.RData"))
```


## Point-referenced data
### Spatial dependency with *point-referenced data* data
The spatial dependence is here model with the SPDE approach. The following steps are required:

*   Create the mesh
*   Create the SPDE
*   Create the matrix of weights 


#### Create the mesh
In order to create the mesh, we start by identifying the *segmentos* for which there are EHPM data. Second, we create a spatial polygon of the boundaries of the country by dissolving the shapefile of the *departentos* with the function `unionSpatialPolygons`. Third, we transform this spatial polygon into a list that the `INLA` library can process with the function `inla.sp2segment`. 

Lastly, we use the helper function `inla.mesh.create.helper` to create the mesh, using the boundary and coordinates of the centroids of the *segmentos* as inputs. 
```{r mesh, message=FALSE, warning=FALSE, fig.cap='Mesh', out.width='200%', fig.width=3, fig.height=3,fig.show='hold',fig.align='center'}
# create the mesh #### 
segmento_sh_subset=subset(segmento_sh_data_model,
                          is.na(segmento_sh_data_model@data$ingpe)==F) # identify where there is EHPM data

coords=coordinates(segmento_sh_subset) # collect the coordinates of the segmentos with EHPM datr
SVborder <- maptools::unionSpatialPolygons(departamentos_sh,
                                           rep(1, nrow(departamentos_sh))) # create one polygone with boundary of the countries
SV.bdry <- inla.sp2segment(SVborder) # create an inla boundary object 

SV.mesh <- inla.mesh.create.helper(
  boundary=SV.bdry,
  points=coords,
  offset=c(2500, 25000),
  max.edge=c(20000, 50000),
  min.angle=c(25, 25),
  cutoff=8000,
  plot.delay=NULL)
plot(SV.mesh,main="",asp=1)
```

The `offset` parameters of `inla.mesh.create.helper` define the inner and outer distance. For instance, if we change the outer offset parameter to 250 km instead of the original 25k, the result is plotted on Fig \@ref(fig:mesh-large).

```{r mesh-large, message=FALSE, warning=FALSE, fig.cap='Mesh', out.width='200%', fig.width=3, fig.height=3,fig.show='hold',fig.align='center'}
SV.meshL <- inla.mesh.create.helper(
  boundary=SV.bdry,
  points=coords,
  offset=c(2500, 250000), # we increased from 25000 to 250000
  max.edge=c(20000, 50000),
  min.angle=c(25, 25),
  cutoff=8000,
  plot.delay=NULL)
plot(SV.meshL,main="",asp=1)
```
When choosing the outer offset parameter, the aim is to avoid the presence of boundary effects in the subsequent estimation of the SPDE. It hence best to allow for a sufficient distance as shown on Fig. \@ref(fig:mesh). However, Fig. \@ref(fig:mesh-large) is clearly too large and would slow down the estimation process. 

The inner offset parameter has no effect here as it is superseded by the `max.edge`, `min.angle` and `cutoff` parameters.The `max.edge` parameters defines the largest allowed triangle edge length. The `min.angle` parameter defines the smallest allowed triangle angle while the parameter `cutoff` defines the minimum allowed distance between points.  

Let us illustrate the impact of modifying the `max.edge` from 20km to 5km. 

```{r mesh-tight, message=FALSE, warning=FALSE, fig.cap='Mesh', out.width='200%', fig.width=3, fig.height=3,fig.show='hold',fig.align='center'}
SV.meshL <- inla.mesh.create.helper(
  boundary=SV.bdry,
  points=coords,
  offset=c(2500, 25000), 
  max.edge=c(20000, 5000), # we decreased from 50000 to 5000
  min.angle=c(25, 25),
  cutoff=8000,
  plot.delay=NULL)
plot(SV.meshL,main="",asp=1)
```
Fig \@ref(fig:mesh-tight) shows the results. The risk of such a tight mesh is to lead to over-fitting. Furthermore, it is computationally more expensive.

#### Derive the SPDE
Next, the SPDE is derived from the mesh thanks to the `inla.spde2.matern` function and the spatial index with the function `inla.spde.make.index`.
```{r  eval=TRUE}
# create the SPDE ####
SV.spde <- inla.spde2.matern(mesh=SV.mesh,alpha=2)

s.index <- inla.spde.make.index(name="spatial.field", n.spde=SV.spde$n.spde) 
```
The `s.index` allows to link the matrix of spatial weights that will be defined below with the mesh
#### Create the matrix of weights
The matrix of weights is created with the `INLA` function `inla.spde.make.A`
```{r  eval=TRUE}
A.train <- inla.spde.make.A(mesh=SV.mesh, loc=coords[index_train,])
A.val <- inla.spde.make.A(mesh=SV.mesh, loc=coords[index_val,])
```
### Store the data for modelling in a stack
Here is we use the `inla.stack` function to store the data conveniently in one object.
```{r  eval=TRUE}
# Stack ####
covariates_list=c("AREA_ID","lights_med","pop_dens","slope","chirps_ev_2017","dist2pubamen","dist2road")

stack.train <- inla.stack(data = list(pred=segmento_sh_subset@data$ingpe[index_train]), # this output variable (income)
                          A = list(A.train, 1,1), 
                          effects = list(s.index, 
                                         Intercept=1:length(index_train), 
                                         segmento_sh_subset@data[index_train,c(covariates_list)]),
                          tag="train") # the tag allows to extract later selected statistics for desired sample

stack.val <- inla.stack(data = list(pred=NA), # we set it to NA
                          A = list(A.val, 1,1), 
                          effects = list(s.index, 
                                         Intercept=1:length(index_val), 
                                         segmento_sh_subset@data[index_val,c(covariates_list)]),
                        tag="val")
# combine both stack
join.stack <- inla.stack(stack.train, stack.val)
```
### Formula specifying the relationship between the outcome variable and the fixed and spatial random effects  
We use the same set of fixed effects. 
```{r  eval=TRUE}
# write the test formula ####
formula_test =pred~ -1+Intercept+
  AREA_ID+lights_med+pop_dens+slope+chirps_ev_2017+dist2pubamen+dist2road+
  f(spatial.field, model=SV.spde)
```

The main difference with the *BYM 2* specification is the  way the spatial random effects are specified by the `f()` function. It takes here two arguments: `spatial.field` is the name of the spatial index `s.index`, the`model` is the SPDE defined in SV.spde.


### Fit the model on the training set 
The same `inla` command is used to fit the SPDE model than when fitting the areal model. The only difference is that the `data` argument takes the stack data defined above as an input. 

```{r  eval=TRUE}
# fit ####
start_time=Sys.time()
spde_res=inla(formula_test, # formula
                      data=inla.stack.data(join.stack), 
                      family="gamma", # likelihood of the data
                      control.predictor=list(A=inla.stack.A(join.stack),
                                             link=1,compute=T))
end_time=Sys.time()
print(end_time-start_time) 
```
The model is much faster to fit: it took only 19 seconds (against 3.5 minutes for the BMY2 model).

### Validate the model on the validation set
We can now investigate the goodness of fit of the model. In order to extract from the `income_spde_test` object the fitted values for the training and the validation set, we use the `inla.stack.index` function. Again,we extracted only the mean predicted value for each *segmento*.

```{r  eval=TRUE}
# Extract fitted values 
index_inla_train = inla.stack.index(join.stack,"train")$data
index_inla_val = inla.stack.index(join.stack,"val")$data

results.train=spde_res$summary.fitted$mean[index_inla_train]
results.val=spde_res$summary.fitted$mean[index_inla_val]

M_fit_spde=array(NA,length(M_fit))
M_fit_spde[index_train]=results.train
M_fit_spde[index_val]=results.val

r2_train_spde=pseudo_r2(index_train,"ingpe",segmento_sh_subset@data,M_fit_spde)
r2_val_spde=pseudo_r2(index_val,"ingpe",segmento_sh_subset@data,M_fit_spde)
rmse_train_spde=RMSE(index_train,"ingpe",segmento_sh_subset@data,M_fit_spde)
rmse_val_spde=RMSE(index_val,"ingpe",segmento_sh_subset@data,M_fit_spde)
```

```{r spde-fit-chunck, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Observed vs predicted income values, SPDE model', out.width='80%', fig.width=3, fig.height=3,fig.show='hold',fig.align='center'}
a <- list(
  x = 600,
  y = 100,
  text = paste("R2 training set:",round(r2_train_spde*100),"%",
               "\nR2 validation set:",round(r2_val_spde*100),"%",
               "\n",
               "\nRMSE training set:",round(rmse_train_spde),"USD",
               "\nRMSE validation set:",round(rmse_val_spde),"USD"),
  
  xref = "x",
  yref = "y",
  showarrow = F)


plotly::plot_ly(y=M_fit_spde[index_train],
                x=segmento_sh_subset@data$ingpe[index_train],
                type="scatter",
                mode="markers",
                name="training set",
                marker = list(color = 'black',
                              opacity = 0.3))%>%
  plotly::add_trace(y=M_fit_spde[index_val],
                    x=segmento_sh_subset@data$ingpe[index_val],
                    mode="markers",
                    name="test set",
                    marker = list(color = 'red',
                                  opacity = 0.3))%>%
  plotly::add_trace(y=c(0,880),
                    x=c(0,880),
                    mode="lines",
                    name="1:1")%>%
  plotly::layout(yaxis=list(range=c(0,510),title="predicted (USD)"),
                 xaxis=list(range=c(0,880),title="observed (USD)"),
                 annotations=a,
                 title="Income at the segmento level")
```

```{r spde-fit, eval=F, echo=FALSE,out.width = '100%',fig.cap='Observed vs predicted income values, SPDE model'}
knitr::include_graphics("img/mini_model_1.PNG")
```

Fig. \@ref(fig:spde-fit) shows the observed values against the predicted values for the training and validation sets. There are no major difference with the results obtained with the modified BYM model shown on Fig.\@ref(fig:bym2-fit), except that here there does not appear to be over-fitting as the $R^{2}$ are similar in the training and validation set.

Let us save the results for later consumption.

```{r eval=T}
income_spde_naive=list("outcome"="ingpe",
                       "spat_dep"="spde",
                       "cov_select"="naive",
                       "formula"=formula_test,
                       "family"="gamma",
                       "data"=join.stack,
                       "fit"=M_fit_spde,
                       "index_val"=index_val,
                       "index_train"=index_train,
                       "r2_val"=r2_val_spde,
                       "r2_train"=r2_train_spde,
                       "RMSE_val"=rmse_val_spde,
                       "RMSE_train"=rmse_train_spde)
save(income_spde_naive,
     file=paste0(dir_data,
            "out/results/income_spde_naive.RData"))
```

Lastly, Fig. \@ref(fig:spde-fit-log) shows the results when using a Gaussian likelihood and log transforming the income data. There is a minor improvement to the goodness of fit compared to the *Gamma* model.

```{r spde-fit-log-chunk, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Observed vs predicted income values, SPDE model with Gaussian likelihood and Log-transformed income values', out.width='80%', fig.width=3, fig.height=3,fig.show='hold',fig.align='center'}
# write the test formula ####
formula_test =log(pred)~ -1+Intercept+
  AREA_ID+lights_med+pop_dens+slope+chirps_ev_2017+dist2pubamen+dist2road+
  f(spatial.field, model=SV.spde)

# fit ####
spde_res=inla(formula_test, # formula
                      data=inla.stack.data(join.stack), 
                      family="gaussian", # likelihood of the data
                      control.predictor=list(A=inla.stack.A(join.stack),
                                             link=1,compute=T))

# Extract fitted values 
index_inla_train = inla.stack.index(join.stack,"train")$data
index_inla_val = inla.stack.index(join.stack,"val")$data

results.train=spde_res$summary.fitted$mean[index_inla_train]
results.val=spde_res$summary.fitted$mean[index_inla_val]

M_fit_spde=array(NA,length(M_fit))
M_fit_spde[index_train]=results.train
M_fit_spde[index_val]=results.val


# compute goodness of fit stats
segmento_sh_subset@data$ln_ingpe=log(segmento_sh_subset@data$ingpe)

r2_train_spde=pseudo_r2(index_train,"ln_ingpe",segmento_sh_subset@data,M_fit_spde)
r2_val_spde=pseudo_r2(index_val,"ln_ingpe",segmento_sh_subset@data,M_fit_spde)
rmse_train_spde=RMSE(index_train,"ln_ingpe",segmento_sh_subset@data,M_fit_spde)
rmse_val_spde=RMSE(index_val,"ln_ingpe",segmento_sh_subset@data,M_fit_spde)

a <- list(
  x = 4,
  y = 6,
  text = paste("R2 training set:",round(r2_train_spde*100),"%",
               "\nR2 validation set:",round(r2_val_spde*100),"%",
               "\n",
               "\nRMSE training set:",round(rmse_train_spde,1),"log USD",
               "\nRMSE validation set:",round(rmse_val_spde,1),"log USD"),
  
  xref = "x",
  yref = "y",
  showarrow = F)


plotly::plot_ly(y=M_fit_spde[index_train],
                x=segmento_sh_subset@data$ln_ingpe[index_train],
                type="scatter",
                mode="markers",
                name="training set",
                marker = list(color = 'black',
                              opacity = 0.3))%>%
  plotly::add_trace(y=M_fit_spde[index_val],
                    x=segmento_sh_subset@data$ln_ingpe[index_val],
                    mode="markers",
                    name="test set",
                    marker = list(color = 'red',
                                  opacity = 0.3))%>%
  plotly::add_trace(y=c(0,8),
                    x=c(0,8),
                    mode="lines",
                    name="1:1")%>%
  plotly::layout(yaxis=list(range=c(3,7),title="predicted (USD)",
                            ticktext = list("50","100","200","300","500","800"), 
                            tickvals = list(3.912023,4.605170,5.298317,5.703782,6.214608,6.684612),
                            tickmode = "array"),
                 xaxis=list(range=c(3,7),
                            title="observed (USD)",
                            ticktext = list("50","100","200","300","500","800"), 
                            tickvals = list(3.912023,4.605170,5.298317,5.703782,6.214608,6.684612),
                            tickmode = "array"),
                 annotations=a,
                 title="Income at the segmento level")

# saving the results
income_spde_naive_gaussian=list("outcome"="ingpe",
                       "spat_dep"="spde",
                       "cov_select"="naive",
                       "formula"=formula_test,
                       "family"="gaussian",
                       "data"=join.stack,
                       "fit"=M_fit_spde,
                       "index_val"=index_val,
                       "index_train"=index_train,
                       "r2_val"=r2_val_spde,
                       "r2_train"=r2_train_spde,
                       "RMSE_val"=rmse_val_spde,
                       "RMSE_train"=rmse_train_spde)
save(income_spde_naive_gaussian,
     file=paste0(dir_data,
            "out/results/income_spde_naive_gaussian.RData"))

```

```{r spde-fit-log, eval=F, echo=FALSE,out.width = '100%',fig.cap='Observed vs predicted income values, SPDE model with Gaussian likelihood and Log-transformed income values'}
knitr::include_graphics("img/mini_model_2.PNG")
```

## *K-fold* cross-validation
The split of the observations between the training and validation sets has important impact on the goodness of fit of the model. Indeed, the model could fit very well the observations in the training set but fit poorly the observations in the validation set purely by chance. 

*K-fold* crossvalidation is a way to assess the robustness of the results to various splits of the data. In *K-fold* crossvalidation, the data a split in *K* folds and each fold is used only once for validation purposes and $K-1$ times for training purpose. At the end of the process, one can assess how the goodness of statistics varies and what is its average value. A typical value for *K* is 10.

The 10 folds are created as follow:
```{r eval=TRUE}
set.seed(1)
spec = c(val1 = .1, val2 = .1, val3 = .1,
         val4 = .1, val5 = .1, val6 = .1,
         val7 = .1, val8 = .1, val9 = .1,
         val10 = .1)
g = sample(cut(
  seq(nrow(data_model)), 
  nrow(data_model)*cumsum(c(0,spec)),
  labels = names(spec)
))
```

We then fit the model 10 times, using each fold as a validation set once.

```{r eval=TRUE}
r2_train_spde_a=r2_val_spde_a=rmse_train_spde_a=rmse_val_spde_a=c() # prepare empty array to store goodness of fit stats
for(k in 1:10){
  # define the index
  index_val=which(g==paste0("val",k))
  index_train=which(g!=paste0("val",k))
  
  # define the weights
  A.train <- inla.spde.make.A(mesh=SV.mesh, loc=coords[index_train,])
  A.val <- inla.spde.make.A(mesh=SV.mesh, loc=coords[index_val,])
  
  # build the stack
  covariates_list=c("AREA_ID","lights_med","pop_dens","slope","chirps_ev_2017","dist2pubamen","dist2road")
  
  stack.train <- inla.stack(data = list(pred=segmento_sh_subset@data$ingpe[index_train]), # this output variable (income)
                            A = list(A.train, 1,1), 
                            effects = list(s.index, 
                                           Intercept=1:length(index_train), 
                                           segmento_sh_subset@data[index_train,c(covariates_list)]),
                            tag="train") # the tag allows to extract later selected statistics for desired sample
  
  stack.val <- inla.stack(data = list(pred=NA), # we set it to NA
                          A = list(A.val, 1,1), 
                          effects = list(s.index, 
                                         Intercept=1:length(index_val), 
                                         segmento_sh_subset@data[index_val,c(covariates_list)]),
                          tag="val")
  
  join.stack <- inla.stack(stack.train, stack.val)
  
  # write the test formula ####
  formula_test =pred~ -1+Intercept+
    AREA_ID+lights_med+pop_dens+slope+chirps_ev_2017+dist2pubamen+dist2road+
    f(spatial.field, model=SV.spde)
  
  # fit the model
  spde_res=inla(formula_test, # formula
                data=inla.stack.data(join.stack), 
                family="gamma", # likelihood of the data
                control.predictor=list(A=inla.stack.A(join.stack),
                                       link=1,compute=T))
  end_time=Sys.time()
  
  # extract the fitted values
  index_inla_train = inla.stack.index(join.stack,"train")$data
  index_inla_val = inla.stack.index(join.stack,"val")$data
  
  results.train=spde_res$summary.fitted$mean[index_inla_train]
  results.val=spde_res$summary.fitted$mean[index_inla_val]
  
  M_fit_spde=array(NA,length(M_fit))
  M_fit_spde[index_train]=results.train
  M_fit_spde[index_val]=results.val
  
  # compute goodness of fit stats
  r2_train_spde=pseudo_r2(index_train,"ingpe",segmento_sh_subset@data,M_fit_spde)
  r2_val_spde=pseudo_r2(index_val,"ingpe",segmento_sh_subset@data,M_fit_spde)
  rmse_train_spde=RMSE(index_train,"ingpe",segmento_sh_subset@data,M_fit_spde)
  rmse_val_spde=RMSE(index_val,"ingpe",segmento_sh_subset@data,M_fit_spde)

  # stores goodness of fit stats in an array
  r2_train_spde_a=c(r2_train_spde_a,r2_train_spde)
  r2_val_spde_a=c(r2_val_spde_a,r2_val_spde)
  rmse_train_spde_a=c(rmse_train_spde_a,rmse_train_spde)
  rmse_val_spde_a=c(rmse_val_spde_a,rmse_val_spde)
  
  # print status
  # print(paste(k, "folds done"))
}
print(paste("Average R2 in the validation set:", round(mean(r2_val_spde_a)*100),"%",
            "\nAverage R2 in the training set:", round(mean(r2_train_spde_a)*100),"%"))

```
The average $R^{2}$ of the validation and training sets (respectively 41% and 47%) are in line with the results obtained with the original split.