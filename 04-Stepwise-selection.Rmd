# Stepwise Covariates Selection {#stepwise}

The goal of this section is to describe a backward stepwise covariates selection process, i.e. a process to reduce the number of covariates from the 50 potential ones identified in section \@ref(explo) to circa 10 or less. Here is an overview of the process:

1.  Split the sample into a 60/20/20 training, validation and test sets;  
2.  Write the test formula without one of the 50 candidate covariates;
3.  Fit the model on the training set;
4.  Validate the model on the validation set and compute goodness of fit statistics;
5.  Repeat step 2 to 4 once for each covariate (50 times);
6.  Drop the covariate in the absence of which the fit us the best;
7.  Repeat steps 2 to 6 until no covariate is left;
8.  Inspect the result to identify a parsimonious specification (typically below 10 covariates) yielding a good fit on the validation set;
9.  Test the final model on the test set.

The backward stepwise covariates selection process is computationally expensive. Fitting one modified BYM model takes around 3.5 minutes on a standard PC^[Processor: Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz, 16.0 GB RAM]. To carry steps 1 to 5, it takes approximately 175 minutes. Step 6 to 7 takes hence approximately  74 hours. In order to speed it up the process, we write a function to parallelise step 5 across CPU cores. As the number of cores might relatively limited on a PC (typically up to 8), an option is to carry the process on the cloud where an instance with more cores can be rented. For instance, the computing time can be reduced to below two hours with 64 cores.    

The backward stepwise covariates selection is presented with the income model.

```{r echo=FALSE, include=FALSE, warning=FALSE,message=FALSE}
rm(list=ls())
library(parallel)
library(INLA)
library(dplyr)

# modify dir_data to where you stored the data
root_dir="C:/Users/Xavier Vollenweider/"
project_dir="Dropbox/IDB_data_pack/data/"
dir_data=paste0(root_dir,project_dir)

# load the data ####
ehpm17_predictors=read.csv(paste0(dir_data,
                                  "out/all_covariates_and_outcomes.csv"))

# correct for xls missbehaviour: the SEG_ID with a leading 0 were shorten
ehpm17_predictors=ehpm17_predictors%>%
  mutate(SEG_ID=as.character(SEG_ID),
         SEG_ID=ifelse(nchar(SEG_ID)==7,
                       paste0(0,SEG_ID),
                       SEG_ID))

# shape
segmento_sh=rgdal::readOGR(paste0(dir_data,
                                  "spatial/shape/admin/STPLAN_Segmentos.shp"))

# add the survey data to shapefile
segmento_sh_data=segmento_sh

segmento_sh_data@data=segmento_sh_data@data%>%
  dplyr::select(SEG_ID)%>%
  mutate(SEG_ID=as.character(SEG_ID))%>%
  left_join(ehpm17_predictors,
            by="SEG_ID")


# define the neighbouring structure #### 
segmento_sh_data@data$ID=1:nrow(segmento_sh_data@data)

# segmento.nb=spdep::poly2nb(segmento_sh_data)
# spdep::nb2INLA(paste0(dir_data,
#                       "out/SEG.graph"),
#                segmento.nb)
# SEG.adj=paste0(paste0(dir_data,
#                       "out/SEG.graph"),
#                sep="")
Segmento.Inla.nb <- INLA::inla.read.graph(paste0(dir_data,
                                                 "out/SEG.graph"))

# identify ehpm17 segmentos to fit the model ####
segmento_sh_data_model=segmento_sh_data 

non_na_index=which(is.na(segmento_sh_data_model$n_obs)==F)

ehpm17_predictors_nona=segmento_sh_data_model@data[non_na_index,]


# covariates #####
cov_candidates_selected_df=read.table(paste0(dir_data,
                                             "out/distance_corr_var/selected_all.txt"),
                                      header =T)
cov_candidates_selected_table=cov_candidates_selected_df
covariates=ehpm17_predictors_nona[,as.character(cov_candidates_selected_df$x)]

# store data for the model ####
data_model=data.frame(ingpe=ehpm17_predictors_nona$ingpe,
                      intercept=array(1,dim(covariates)[1]), # intercept for INLA
                      ID=ehpm17_predictors_nona$ID, # ID to link data to the neibhouring structure
                      covariates)
covariates_formulation=colnames(covariates)
```

##  Step 1: Split the sample into a 60/20/20 training, validation and test sets  
The observations in the dataset are split into a 60/20/20 training, validation and test sets. The model will be fitted on the training set. Income will be predicted on the training and validation sets. Predicted values in the validation set will be compared with the observed values in order to assess the goodness of it of the model. 

Once the covariate selection process is complete and a given specification has been chosen (steps 1 to 8 above), prediction are made on the final test set to assess the goodness of fit of the final model. 

```{r}
# sample segmentos for training, validation and test  ####
set.seed(1234)
spec = c(train = .6, test = .2, validate = .2)
g = sample(cut(
  seq(nrow(data_model)), 
  nrow(data_model)*cumsum(c(0,spec)),
  labels = names(spec)
))
index_val=which(g=="validate")
index_train=which(g=="train")
index_test=which(g=="test")

data_model$pred=data_model$ingpe
data_model$pred[c(index_val,index_test)] <- NA # set the validation pred to NA: they will be predicted by the model and compared with observed values 

mod_data_jack = data_model # store data into a new dataframe for model fitting      
mod_data_jack=mod_data_jack[c(index_val,index_train),] # select only the training and validation sets, keep test set of final validation
index_val_jack=which(is.na(mod_data_jack$pred))
index_train_jack=which(is.na(mod_data_jack$pred)==F)
```

## Bundle step 2 to 4 in a function
In order to ease the reading of the code, we create a function `INLA_steps_2_4` implementing steps 2 to 4 of the covariate selection process. The `INLA_steps_2_4`:

1.  Write the test formula without one of the candidate covariates;
2.  Fit the model on the training set;
3.  Validate the model on the validation set;
4.  Compute goodness of fit statistics.

The `INLA_steps_2_4` accepts the following arguments:
- covariates formulation
- index of the covariate to be removed
- index of the validation set
- index of the training set
- dataframe for the model
- a string defining the outcome variable, e.g. "ingpe"
- a string defining the likelihood function, e.g. Gaussian, Gamma or a Beta distribution

```{r}
# INLA_set2_4_function #####
INLA_steps_2_4=function(covariates_formulation, # formulation of each covariate
                        ix, # the index of the covariate to be removed
                        index_val, # index of the validation set
                        index_train, # index of the training set
                        mod_data_jack, # data for the model
                        outcome,   # string defining the outcome variable, e.g. ingpe
                        family){   # string defining the likelihood 
  
  # formula
  candidate_covariates <- covariates_formulation 
  
  formula_test <- reformulate(c("-1", "intercept",
                                paste(candidate_covariates[-ix],collapse="+"),
                                'f(ID,model = "bym2",
                                hyper=list(
                                prec = list(prior = "pc.prec", param = c(0.1, 0.0001)),
                                phi  = list(prior = "pc", param = c(0.5, 0.5))),
                                graph = Segmento.Inla.nb,
                                scale.model = TRUE,
                                constr = T,
                                adjust.for.con.comp = T)'),
                              "pred") # rescale to allow the Newton-Raphson optimizer to converge
  
  if(family=="gaussian"){
    formula_test <- reformulate(c("-1", "intercept",
                                  paste(candidate_covariates[-ix],collapse="+"),
                                  'f(ID,model = "bym2",
                                hyper=list(
                                prec = list(prior = "pc.prec", param = c(0.1, 0.0001)),
                                phi  = list(prior = "pc", param = c(0.5, 0.5))),
                                graph = Segmento.Inla.nb,
                                scale.model = TRUE,
                                constr = T,
                                adjust.for.con.comp = T)'),
                                "pred/10") # rescale to allow the Newton-Raphson optimizer to converge
  }
  # fit the model
  if(family%in%c("beta","zeroinflatedbinomial1")){
    bym.res=INLA::inla(formula=formula_test, 
                       family = family, 
                       data = mod_data_jack,
                       Ntrials = mod_data_jack$n_obs,
                       control.predictor=list(link=1,compute=T),
                       control.compute=list(dic=T, cpo=F),
                       control.inla =list(int.strategy = "eb")
    )
  }else{
    
    bym.res=INLA::inla(formula=formula_test, 
                       family = family, 
                       data = mod_data_jack,
                       control.predictor=list(link=1,compute=T),
                       control.compute=list(dic=T, cpo=F),
                       control.inla =list(int.strategy = "eb") 
    )
  }
  # extact fitted values
  M_fit=bym.res$summary.fitted.values[,"mean"]
  
  if(family%in%c("gamma")){
    M_fit=exp(M_fit) # back transform to level
  }
  if(family%in%c("gaussian")){
    M_fit=M_fit*10 # back transform to level
  }
  
  # funcion for RMSE 
  RMSE=function(set,outcome,data){
    res = data[set,outcome]-M_fit[set]
    RMSE_val <- sqrt(mean(res^2,na.rm=T)) 
    return(RMSE_val)  
  }
  # funcion for pseudo_r2
  pseudo_r2=function(set,outcome,data){
    res =  data[set,outcome]-M_fit[set]
    RRes=sum((res)^2,na.rm = T)
    RRtot=sum((data[set,outcome]-mean(M_fit[set],na.rm=T))^2,na.rm = T)
    pseudo_r2_val=1-RRes/RRtot
    return(pseudo_r2_val)  
  }
  
  # RMSE: RMSE  function defined above
  RMSE_val=RMSE(index_val,outcome,mod_data_jack)
  RMSE_train=RMSE(index_train,outcome,mod_data_jack)
  
  # R2: pseudo_r2 function defined above
  r2_val=pseudo_r2(index_val,outcome,mod_data_jack)
  r2_train=pseudo_r2(index_train,outcome,mod_data_jack)
  
  # store results
  results_list=list("cov_i"=ix,
                    "cov_name"=candidate_covariates[ix],
                    "formula"=formula_test,
                    # "fitted_values"=M_fit,
                    # "index_val"=index_val,
                    # "index_train"=index_train,
                    # "index_train_val"=index_train_val,
                    "RMSE_val"=RMSE_val,
                    "RMSE_train"=RMSE_train,
                    "r2_val"=r2_val,
                    "r2_train"=r2_train,
                    "outcome"=outcome,
                    "family"=family)
  rm(bym.res)
  return(results_list)
}
```

We can now test the function.
```{r warning=FALSE, message=FALSE}
# test the function #####
test_fct=INLA_steps_2_4(covariates_formulation, # formulation of each covariate
                        1, # the index of the covariate to be removed
                        index_val_jack, # index of the validation set
                        index_train_jack, # index of the validation set
                        mod_data_jack, # data for the model
                        "ingpe", # outcome
                        "gaussian") # likelihood
```
The results can then be accessed using the `$` sign. For instance, we can look at the $R^2$:

```{r}
print(paste("R-squared in the validation set:",test_fct$r2_val,
            "R-squared in the training set:",test_fct$r2_train))
```


## Bundle step 5 to 7 in a loop ran in parallel
We can now launch the entire backward selection process with a loop. In order to speed up the process, we parallelise the estimation of each single model across the cores: each core is in charge of estimating one model. In the first iteration of the loop, we start with a list of $50$ candidate covariates. $50$ models are estimated. Each model contains all covariates minus one $j$ covariate, where $j$ is different in each model and $j=1, ..., 50$. Once the $50$ models have been estimated, results are collected and the best performing model is identified, say model *k* The corresponding $k$ covariate is removed from the list of candidate covariate and the loop proceed to the next iteration with a list of $50-1=49$ candidate covariates.

```{r eval=F}
# loop over all covariates until only 1 is left #####
candidate_covariates=covariates_formulation # start again with the full list of candidate covariate
n2drop=length(covariates_formulation)-1 
start_t=Sys.time()
results_jacknife=list() # create a list to store all the results of the jacknife selectio process
for(n_cov_to_drop in 1:n2drop){  # repeat the step n2drop=12 times until having only 8 covariates
  
  set.seed(101)
  
  INLA_steps_2_4_par=function(cov_n){  # fit the model dropping one covariates after the other
    model_fct=INLA_steps_2_4(candidate_covariates, # formulation of each covariate
                             cov_n, # the index of the covariate to be removed
                             index_val_jack, # index of the validation set
                             index_train_jack, # index of the validation set
                             mod_data_jack,  # data for the model
                             "ingpe", # outcome
                             "gaussian") # likelihood
    cat("\014") # clean the consol
    # end_t=Sys.time()
    # duration=end_t-start_t
    # print(duration)
    return(model_fct)
  }
  cov_n<-1:length(candidate_covariates)
  n_cores<-detectCores()
  cl=makeCluster(n_cores)
  start_T<-Sys.time()
  clusterExport(cl=cl,
                varlist=c("candidate_covariates",
                          "INLA_steps_2_4",
                          "index_val_jack",
                          "index_train_jack",
                          "mod_data_jack",
                          "Segmento.Inla.nb"))
  results_list<-clusterApply(cl,cov_n,INLA_steps_2_4_par)
  end_T<-Sys.time()
  cat("\014") # clean the consol
  print(end_T-start_T)
  stopCluster(cl)
  gc()
  # store all the results for quality check
  results_jacknife[[n_cov_to_drop]]=results_list 
  
  # drop covariate affecting the least the goodness of fit 
  
  rmse_val=lapply(results_list,function(x) unlist(x$RMSE_val))
  rmse_val_min=which.min(rmse_val)
  
  covariates_to_be_removed=results_list[[rmse_val_min]]$cov_name
  
  candidate_covariates=candidate_covariates[-which(candidate_covariates==covariates_to_be_removed)]
  rm(results_list)
  print(paste(length(candidate_covariates),"covariates remaining"))
  
}
end_t=Sys.time()
duration=end_t-start_t
print(duration) # 1.84 hours
```
The process took slightly less than 2 hours on a cloud instance with 64 cores.

## Step 8: Inspect the results and select specification
We can now inspect the results of the selection process. Let us look at the goodness of fit of the best performing models at each covariate selection step, using the R-squared and the RMSE as goodness of fit statistics.  


```{r warning=FALSE, message=FALSE, eval=T}
# INCOME Bym2 ####
load(paste0(dir_data,"workspace/income_bym2_gaussian.RData"))

# visualize R2  ####
# extract r2
r2_val_max=r2_train_max=r2_val_min=r2_train_min=c()
for(k in 1:length(results_jacknife)){
  r2_val=lapply(results_jacknife[[k]],function(x) unlist(x$r2_val))
  r2_train=lapply(results_jacknife[[k]],function(x) unlist(x$r2_train))
  
  # get max r2
  r2_val_max_index=which.max(r2_val)
  r2_val_max_i=r2_val[[r2_val_max_index]]
  r2_train_max_i=r2_train[[r2_val_max_index]]
  
  r2_val_max=c(r2_val_max,r2_val_max_i)
  r2_train_max=c(r2_train_max,r2_train_max_i)
  
  # get min r2
  r2_val_min_index=which.min(r2_val)
  r2_val_min_i=r2_val[[r2_val_min_index]]
  r2_train_min_i=r2_train[[r2_val_min_index]]
  
  r2_val_min=c(r2_val_min,r2_val_min_i)
  r2_train_min=c(r2_train_min,r2_train_min_i)
}

# viz r2
data2plot=data.frame(set=c(rep("val",length(r2_val_max)),rep("train",length(r2_val_max))),
                     index=c(rev(1:length(r2_val_max)),rev(1:length(r2_val_max))),
                     index_jack=c(1:length(r2_val_max),1:length(r2_val_max)),
                     r2_max=c(unlist(r2_val_max),unlist(r2_train_max)),
                     r2_min=c(unlist(r2_val_min),unlist(r2_train_min)))

plotly::plot_ly(data=data2plot,
                x=~index_jack,
                y=~r2_max,
                name = ~set,
                type="scatter",
                mode="line")
```

```{r jack-r2, eval=F,echo=FALSE,out.width = '100%',fig.cap='R-squared evolution over Jacknife covariates selection process'}
knitr::include_graphics("img/jack_r2.PNG")
```

```{r eval=T}
# visualize RMSE  ####
# extract RMSE
RMSE_val_max=RMSE_train_max=RMSE_val_min=RMSE_train_min=c()
for(k in 1:length(results_jacknife)){
  RMSE_val=lapply(results_jacknife[[k]],function(x) unlist(x$RMSE_val))
  RMSE_train=lapply(results_jacknife[[k]],function(x) unlist(x$RMSE_train))
  
  # get max RMSE
  RMSE_val_max_index=which.max(RMSE_val)
  RMSE_val_max_i=RMSE_val[[RMSE_val_max_index]]
  RMSE_train_max_i=RMSE_train[[RMSE_val_max_index]]
  
  RMSE_val_max=c(RMSE_val_max,RMSE_val_max_i)
  RMSE_train_max=c(RMSE_train_max,RMSE_train_max_i)
  
  # get min RMSE
  RMSE_val_min_index=which.min(RMSE_val)
  RMSE_val_min_i=RMSE_val[[RMSE_val_min_index]]
  RMSE_train_min_i=RMSE_train[[RMSE_val_min_index]]
  
  RMSE_val_min=c(RMSE_val_min,RMSE_val_min_i)
  RMSE_train_min=c(RMSE_train_min,RMSE_train_min_i)
}

# viz RMSE
data2plot=data.frame(set=c(rep("val",length(RMSE_val_max)),rep("train",length(RMSE_val_max))),
                     index=c(rev(1:length(RMSE_val_max)),rev(1:length(RMSE_val_max))),
                     RMSE_max=c(unlist(RMSE_val_max),unlist(RMSE_train_max)),
                     RMSE_min=c(unlist(RMSE_val_min),unlist(RMSE_train_min)))

plotly::plot_ly(data=data2plot,
                x=~index,
                y=~RMSE_min,
                name = ~set,
                type="scatter",
                mode="line")
```
```{r jack-rmse, eval=F, echo=FALSE,out.width = '100%',fig.cap='RMSE evolution over Jacknife covariates selection process'}
knitr::include_graphics("img/jack_rmse.PNG")
```
Based on the results above, the 31st step appears to provide a good balance between the sparsity of the formulation and the goodness of fit.

```{r}
# identify the specification ####
step_chosen=31  
r2_val=lapply(results_jacknife[[step_chosen]],function(x) unlist(x$r2_val))
r2_val_max_index=which.max(r2_val)

formula_selected=results_jacknife[[step_chosen]][[r2_val_max_index]]$formula
formula_selected
```

Here is the list of covariates that were selected:

*   chirps_ev_med: median precipitation
*   lights_med: median lights over the year
*   dist2coast_r: distance to coast
*   pop_dens: population density
*   lc_tree: percentage of trees
*   dens_all_roads: road density (all road categories)
*   dens_secondary: secondary road density 
*   dens_bus : bus lanes density
*   LZ_CentralIndusServ: Central Livelihood zones on industry and services. 

## Step 9 Final test
Lastly, we perform the final test of goodness of fit on the test set. As a reminder, the test set comprise of 20% of the data we set aside before starting the selection process, i.e. the model has not yet *seen* them.


We start by building the dataframe for estimating the final model with the training and test set only.
```{r eval=T}
# build dataframe for final test ####
data_test=data_model
data_test$pred=data_test$ingpe # create a pred variables equal to ingpe, the outcome variable
# data_test$pred[index_test] <- NA # set the test pred to NA: they will be predicted by the model and compared with observed 
data_test$pred[c(index_test, index_val)] <- NA # set the test pred to NA: they will be predicted by the model and compared with observed 
data_test=data_test[c(index_test,index_train),]

index_train_bis=which(is.na(data_test$pred)==F)
index_test_bis=which(is.na(data_test$pred))
```
The estimation is done with the usual `inla` function and results are plotted on Fig. \@ref(fig:test-bym2).  
```{r message=FALSE, warning=FALSE, echo=FALSE, eval=T}
bym_income=INLA::inla(formula=formula_selected, 
                      family = "gaussian", 
                      data = data_test,
                      control.predictor=list(link=1,compute=T),
                      control.compute=list(dic=T, cpo=F),
                      control.inla =list(int.strategy = "eb") 
)

# check goodness of fit of final test ####
M_fit=bym_income$summary.fitted.values[,"mean"]
M_fit=M_fit*10

pseudo_r2=function(set,outcome){
  res =  data_test[set,outcome]-M_fit[set]
  RRes=sum((res)^2,na.rm = T)
  RRtot=sum((data_test[set,outcome]-mean(M_fit[set],na.rm=T))^2,na.rm = T)
  pseudo_r2_val=1-RRes/RRtot
  return(pseudo_r2_val)  
}

RMSE=function(set,outcome,data){
  res = data[set,outcome]-M_fit[set]
  RMSE_val <- sqrt(mean(res^2,na.rm=T)) 
  return(RMSE_val)  
}

RMSE_train=RMSE(index_train_bis,"ingpe",data_test)
RMSE_test=RMSE(index_test_bis,"ingpe",data_test)
r2_train=pseudo_r2(index_train_bis,"ingpe")
r2_test=pseudo_r2(index_test_bis,"ingpe")
```
```{r test-bym2-chunk, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Observed vs predicted income values, BYM 2 model with covariates selected with the backward stepwise selection process', out.width='80%', fig.width=3, fig.height=3,fig.show='hold',fig.align='center', eval=T}
a <- list(
  x = 600,
  y = 100,
  text = paste("R2 training set:",round(r2_train*100),"%",
               "\nR2 test set:",round(r2_test*100),"%",
               "\n",
               "\nRMSE training set:",round(RMSE_train),"USD",
               "\nRMSE test set:",round(RMSE_test),"USD"),
  
  xref = "x",
  yref = "y",
  showarrow = F)


plotly::plot_ly(y=M_fit[-index_val],
                x=data_test$ingpe[-index_val],
                type="scatter",
                mode="markers",
                name="training set",
                marker = list(color = 'black',
                              opacity = 0.3))%>%
  plotly::add_trace(y=M_fit[index_val],
                    x=data_test$ingpe[index_val],
                    mode="markers",
                    name="validation set",
                    marker = list(color = 'red',
                                  opacity = 0.3))%>%
  plotly::add_trace(y=c(0,880),
                    x=c(0,880),
                    mode="lines",
                    name="1:1")%>%
  plotly::layout(yaxis=list(range=c(0,510),title="predicted (USD)"),
                 xaxis=list(range=c(0,880),title="observed (USD)"),
                 annotations=a,
                 title="Income at the segmento level")
```

```{r test-bym2, eval=F, echo=FALSE,out.width = '100%',fig.cap='Observed vs predicted income values, BYM 2 model with covariates selected with the backward stepwise selection process'}
knitr::include_graphics("img/ingpe_fit_obs.PNG")
```